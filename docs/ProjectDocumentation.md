---
id: ProjectDocumentation
aliases: []
tags: []
---

id: ProjectDocumentation
aliases: []
tags: []

---

# Mario RL Agent - Project Documentation

## Project Overview

This project represents my first hands-on exploration of machine learning through applied practice. Rather than starting with pure theory, I'm building a reinforcement learning agent that can learn to play Super Mario Bros. This practical approach will teach me fundamental ML concepts including neural networks, training pipelines, experiment tracking, and model evaluationâ€”all while working on an engaging, tangible problem.

The ultimate goal extends beyond Mario: I'm building skills and establishing workflows that will transfer to my career goal of applying machine learning to cybersecurity applications, specifically around Suricata rule generation and intelligent incident reporting.

## Project Architecture

### Directory Structure

```
mlp/
â”œâ”€â”€ configs/              # Hyperparameter configurations (YAML files)
â”œâ”€â”€ data/                 # Training logs, gameplay videos, episode data
â”œâ”€â”€ database/             # SQL schemas, migration scripts for experiment metadata
â”œâ”€â”€ docker/               # Dockerfiles for containerized training/deployment
â”œâ”€â”€ docs/                 # Project documentation and notes (Obsidian vault)
â”‚   â”œâ”€â”€ daily/           # Daily logs and progress notes
â”‚   â””â”€â”€ ProjectDocumentation.md
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/       # CI/CD pipelines for automated testing
â”œâ”€â”€ models/              # Saved model checkpoints and weights
â”œâ”€â”€ notebooks/           # Jupyter notebooks for analysis and exploration
â”œâ”€â”€ src/                 # Source code
â”‚   â”œâ”€â”€ agents/         # RL agent implementations (DQN, PPO)
â”‚   â”œâ”€â”€ environments/   # Gym environment wrappers and preprocessing
â”‚   â”œâ”€â”€ models/         # Neural network architectures
â”‚   â”œâ”€â”€ preprocessing/  # Frame stacking, normalization, feature extraction
â”‚   â”œâ”€â”€ training/       # Training loops and callbacks
â”‚   â””â”€â”€ utils/          # Helper functions and utilities
â”œâ”€â”€ tests/              # Unit tests for components
â”œâ”€â”€ pyproject.toml      # Poetry dependency management
â”œâ”€â”€ README.md           # Project overview and quick start
â””â”€â”€ .gitignore         # Git ignore rules
```

### Key Components

- **Training Pipeline**: Orchestrates the full training workflow from environment initialization through model checkpointing
- **Agent Architecture**: Implements RL algorithms (DQN, PPO) with configurable hyperparameters
- **Environment Wrapper**: Preprocesses game frames and manages observation/action spaces
- **Data Storage**: PostgreSQL database for experiment metadata, hyperparameters, and results
- **Experiment Tracking**: MLflow for model versioning and Weights & Biases for real-time metrics

## Technology Stack

### Core ML Frameworks

- **PyTorch**: Deep learning framework for neural networks
- **Stable-Baselines3**: Production-ready RL algorithm implementations
- **Gymnasium**: Standard RL environment interface
- **gym-super-mario-bros**: NES Mario environment wrapper
- **scikit-learn**: Classical ML algorithms and utilities

### Data & Infrastructure

- **PostgreSQL**: Relational database for experiment tracking
- **SQLAlchemy**: Python ORM for database interactions
- **Pandas**: Data manipulation and analysis
- **DVC**: Data version control for datasets and models
- **MLflow**: Model registry and experiment tracking
- **Weights & Biases**: Real-time training visualization

### Development Tools

- **Poetry**: Python dependency management
- **Docker**: Containerization for reproducible environments
- **GitHub Actions**: CI/CD for automated testing and deployment
- **pytest**: Unit testing framework
- **black**: Code formatting
- **ruff**: Fast Python linting
- **mypy**: Static type checking

### Analysis & Visualization

- **Jupyter Lab**: Interactive notebooks for exploration
- **Plotly**: Interactive visualizations
- **Seaborn**: Statistical graphics
- **TensorBoard**: Training metrics visualization

## Implementation Phases

### Phase 1: Environment Setup âœ… Complete (Dec 26-29, 2025)

- [x] Create project directory structure âœ… 2025-12-26
- [x] Initialize Git repository and GitHub connection âœ… 2025-12-26
- [x] Set up Poetry for dependency management âœ… 2025-12-26
- [x] Configure documentation system (Obsidian) âœ… 2025-12-26
- [x] Install core dependencies (PyTorch, Gymnasium, gym-super-mario-bros) âœ… 2025-12-27
- [x] Set up Python virtual environment âœ… 2025-12-27
- [x] Initialize PostgreSQL database âœ… 2025-12-28
- [x] Create database schema for experiments âœ… 2025-12-29
- [x] Set up Weights & Biases account and project âœ… 2025-12-29
- [x] Configure pre-commit hooks for code quality âœ… 2025-12-29

### Phase 2: Baseline Agent âœ… COMPLETE (Dec 30-31, 2025)

- [x] Install and test gym-super-mario-bros environment âœ… 2025-12-30
- [x] Implement random agent to understand environment mechanics âœ… 2025-12-31
- [x] Build frame preprocessing pipeline: âœ… 2025-12-31
  - [x] Grayscale conversion âœ… 2025-12-31
  - [x] Frame resizing âœ… 2025-12-31
  - [x] Frame stacking (temporal context) âœ… 2025-12-31
  - [x] Normalization âœ… 2025-12-31
- [x] Create first Jupyter notebook for environment exploration âœ… 2025-12-31
- [x] Log baseline experiment to Weights & Biases âœ… 2025-12-31
- [x] Enhanced baseline with 13 comprehensive metrics âœ… 2025-12-31
- [x] Database schema migration for episode metrics âœ… 2025-12-31
- [~] Record and save gameplay videos âš ï¸ Deferred (see note below)

**Phase 2 Achievements:**
- Random baseline: avg reward ~380, max x_pos 434, 0/10 level completions
- Enhanced metrics: 13 tracked values (x_pos, score, time, coins, life, status, flag_get, etc.)
- wandb cloud integration with authentication and real-time logging
- PostgreSQL schema extended with 8 new episode metric columns
- Success criteria defined: x_pos > 434, score â‰¥ 100, flag_get = True

**Video Recording Note:**
Attempted multiple approaches (RecordVideo wrapper, manual imageio frame collection) but discovered gym-super-mario-bros has render_mode='rgb_array' compatibility issues (unmaintained since 2019). Videos created but contain static frames. **Decision: Proceed with metrics-only approach.** Comprehensive wandb tracking provides sufficient baseline proof. Video recording deferred to Phase 3 with alternative approach (render_mode='human' + screen recording).

### Phase 3: Simple RL Algorithm (Weeks 3-5, Jan-Feb 2026)

- [ ] Implement DQN using Stable-Baselines3 ğŸ“… 2026-01-15
- [ ] Create YAML configuration system for hyperparameters ğŸ“… 2026-01-17
- [ ] Build training loop with: ğŸ“… 2026-01-22
  - [ ] Model checkpointing ğŸ“… 2026-01-19
  - [ ] Progress logging ğŸ“… 2026-01-20
  - [ ] Early stopping conditions ğŸ“… 2026-01-22
- [ ] Track key metrics: ğŸ“… 2026-01-24
  - [ ] Episode reward (total points scored) ğŸ“… 2026-01-23
  - [ ] Episode length (frames survived) ğŸ“… 2026-01-23
  - [ ] Training loss ğŸ“… 2026-01-24
  - [ ] Q-value estimates ğŸ“… 2026-01-24
- [ ] Store all experiment metadata in PostgreSQL ğŸ“… 2026-01-26
- [ ] Create analysis notebook comparing random vs. trained agent ğŸ“… 2026-01-29
- [ ] Generate training curve visualizations ğŸ“… 2026-01-31
- [ ] Implement model evaluation pipeline ğŸ“… 2026-02-02

### Phase 4: Advanced Techniques (Weeks 6-9, Feb-Mar 2026)

- [ ] Implement PPO algorithm (often better for platformers) ğŸ“… 2026-02-05
- [ ] Experiment with curriculum learning: ğŸ“… 2026-02-12
  - [ ] Train on easier levels first ğŸ“… 2026-02-09
  - [ ] Gradually increase difficulty ğŸ“… 2026-02-12
- [ ] Implement reward shaping: ğŸ“… 2026-02-19
  - [ ] Reward for distance traveled ğŸ“… 2026-02-15
  - [ ] Penalty for time spent idle ğŸ“… 2026-02-17
  - [ ] Bonus for collecting coins/powerups ğŸ“… 2026-02-19
- [ ] Add sophisticated preprocessing: ğŸ“… 2026-02-26
  - [ ] Attention mechanisms ğŸ“… 2026-02-23
  - [ ] State representation learning ğŸ“… 2026-02-26
- [ ] Systematic hyperparameter tuning: ğŸ“… 2026-03-05
  - [ ] Learning rate schedules ğŸ“… 2026-03-01
  - [ ] Network architecture variations ğŸ“… 2026-03-03
  - [ ] Exploration/exploitation balance ğŸ“… 2026-03-05
- [ ] A/B testing framework for comparing configurations ğŸ“… 2026-03-08

### Phase 5: Production & Analysis (Weeks 10-12, Mar 2026)

- [ ] Containerize training environment with Docker: ğŸ“… 2026-03-15
  - [ ] Multi-stage build (training vs. inference) ğŸ“… 2026-03-12
  - [ ] GPU support configuration ğŸ“… 2026-03-15
- [ ] Set up GitHub Actions workflows: ğŸ“… 2026-03-22
  - [ ] Run tests on pull requests ğŸ“… 2026-03-18
  - [ ] Code quality checks (black, ruff, mypy) ğŸ“… 2026-03-19
  - [ ] Automated model evaluation ğŸ“… 2026-03-22
- [ ] Create comprehensive data analysis dashboards: ğŸ“… 2026-03-29
  - [ ] Training stability analysis ğŸ“… 2026-03-25
  - [ ] Hyperparameter correlation studies ğŸ“… 2026-03-27
  - [ ] Performance comparison across algorithms ğŸ“… 2026-03-29
- [ ] Build model evaluation pipeline: ğŸ“… 2026-04-03
  - [ ] Standardized test episodes ğŸ“… 2026-03-31
  - [ ] Statistical significance testing ğŸ“… 2026-04-02
  - [ ] Performance benchmarking ğŸ“… 2026-04-03
- [ ] Write comprehensive documentation: ğŸ“… 2026-04-10
  - [ ] API documentation ğŸ“… 2026-04-05
  - [ ] Training guides ğŸ“… 2026-04-07
  - [ ] Architecture decisions ğŸ“… 2026-04-09
  - [ ] Lessons learned ğŸ“… 2026-04-10

### Phase 6: Extensions (Ongoing, Apr 2026+)

- [ ] Expand to other games: ğŸ“… 2026-04-15
  - [ ] Sonic the Hedgehog ğŸ“… 2026-04-15
  - [ ] Contra ğŸ“… 2026-04-20
  - [ ] Custom environments ğŸ“… 2026-04-25
- [ ] Implement curiosity-driven exploration ğŸ“… 2026-05-01
- [ ] Multi-agent training (competitive/cooperative) ğŸ“… 2026-05-10
- [ ] Transfer learning between game levels ğŸ“… 2026-05-20
- [ ] Model distillation (compress large models) ğŸ“… 2026-06-01
- [ ] Real-time inference optimization ğŸ“… 2026-06-10
- [ ] Web dashboard for live agent monitoring ğŸ“… 2026-06-20

## Future Applications

Skills and tools developed in this project will directly transfer to cybersecurity applications:

- **ML-Enhanced Suricata Rules**: Apply anomaly detection and pattern recognition to network traffic
- **Intelligent Incident Management**: Use clustering and classification for alert correlation
- **Threat Intelligence**: Automated IOC extraction and threat classification
- **Data Pipeline Experience**: Transfer PostgreSQL, MLflow, and visualization skills to security operations

## Links & Resources

- [GitHub Repository](https://github.com/BrendonJL/mlp)
- [Project Documentation](./ProjectDocumentation.md) (this file)
- [Training Notebooks](../notebooks/)
- [Daily Notes](./daily/)

## Notes

_This document will be updated as the project evolves. Use Obsidian's linking features to connect related concepts and create daily logs of progress._
