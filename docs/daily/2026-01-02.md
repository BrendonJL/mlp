---
id: "2026-01-02"
aliases: []
tags:
  - daily-notes
  - mario-rl-project
  - phase-3
  - dqn-learning
  - database-utilities
  - yaml-config
created: 2026-01-02
---
# ðŸ“… Thursday, January 2, 2026

> _Week 1 of 2026 - Phase 3 Begin!_

## ðŸŽ¯ Today's Goals

- [x] Learn DQN concepts (Q-learning, experience replay, target networks)
- [x] Design YAML configuration system for experiments
- [x] Create config loader utility
- [x] Simplify Mario action space (256 â†’ useful subset)
- [x] Build database logging utilities with connection pooling
- [x] Make progress on Phase 3: Simple RL Algorithm

## âœ… What I Accomplished

### Morning Session: DQN Conceptual Learning

- [x] Watched DeepMind DQN videos and Arxiv Insights explanations âœ…
- [x] Read OpenAI Spinning Up Q-learning documentation âœ…
- [x] Studied Stable-Baselines3 DQN documentation âœ…
- [x] Understood key DQN concepts: Q-function, Bellman equation, bootstrapping âœ…
- [x] Learned about experience replay buffer and target networks âœ…

### Afternoon Session: Infrastructure Development

**Task 1: YAML Configuration System** âœ…
- [x] Designed experiment configuration structure (experiment, environment, hyperparameters, training, paths, database, wandb)
- [x] Created `configs/dqn_baseline.yaml` with 2M timesteps, CnnPolicy, SIMPLE_MOVEMENT actions
- [x] Configured training parameters: save every 100k steps, eval every 10k steps

**Task 2: Config Loader Utility** âœ…
- [x] Installed PyYAML for config parsing
- [x] Created `src/utils/config_loader.py` with `load_config()` function
- [x] Tested loading and parsing YAML configuration

**Task 3: Simplify Action Space** âœ…
- [x] Created `src/environments/mario_env.py` helper function
- [x] Integrated JoypadSpace wrapper with SIMPLE_MOVEMENT
- [x] Reduced actions from 256 â†’ 7 (right, left, jump, jump+right, etc.)
- [x] Tested full environment pipeline: (240,256,3) â†’ (84,84,4) with 7 actions

**Task 4: Database Logging Utilities** âœ…
- [x] Implemented connection pooling with psycopg2 (singleton pattern)
- [x] Created `create_experiment()` - inserts experiment metadata, returns ID
- [x] Created `log_hyperparameters()` - batch inserts key-value pairs
- [x] Created `log_episode()` - inserts episode results (13 metrics)
- [x] Created `update_experiment()` - updates final status and episode count
- [x] Created `log_training_metrics()` - optional periodic metrics logging
- [x] Fixed Pyright type errors with proper cursor handling and assertions

## ðŸ§  What I Learned

### DQN Algorithm Fundamentals

- **Credit assignment problem**: DQN solved learning from raw pixels without human feature engineering - revolutionary in 2013
- **Q-function**: Q(state, action) â†’ expected future reward from taking action in state
- **Bellman equation**: Q(s,a) = r + Î³ Ã— max Q(s',a') - recursive relationship for optimal Q-values
- **Bootstrapping**: Using network's own predictions to create training labels (circular but converges!)
- **Experience replay**: Random sampling from replay buffer breaks temporal correlations, stabilizes training
- **Target network**: Slow-updating copy of Q-network provides stable labels, prevents oscillation
- **DQN efficiency**: Output Q-values for ALL actions in one forward pass (vs. calling network per action)
- **Model-free learning**: No environment model needed, learns purely from experience

### YAML Configuration Management

- **YAML vs. Python**: YAML is data format, not code - no imports allowed!
- **Configuration vs. audit trail**: YAML stores "what I want to run", database stores "what actually ran"
- **Reproducibility**: YAML in Git + database logs = complete experiment history
- **String values in YAML**: Always quote strings to avoid parsing issues
- **PyYAML usage**: `yaml.safe_load(f)` parses YAML â†’ Python dict

### Database Connection Pooling

- **Singleton pattern**: Create pool once, reuse throughout application
- **Pool benefits**: Reuses connections (faster), better for frequent operations
- **SimpleConnectionPool**: min/max connections, get/put pattern
- **Parameterized queries**: ALWAYS use `%s` placeholders, never f-strings (SQL injection prevention!)
- **Defensive programming**: Initialize `cursor = None`, check `if cursor:` before closing
- **Type annotations**: `cursor: Optional[Cursor] = None` + assertions tell Pyright the type
- **fetchone() can return None**: Must assert result before subscripting

### Python Dictionary Operations

- **Looping through dict**: `for key, value in my_dict.items():`  gives both
- **Dictionary access**: `my_dict["key"]` NOT `["key"]` (list creation)
- **Type safety**: Optional types require assertions or checks before use

### LSP/Pyright Type Checking

- **reportMissingImports** vs **reportMissingModuleSource**: Different severity levels
- **Type stubs**: C extensions (psycopg2, gym-super-mario-bros) don't have type info
- **Pyright Python path**: LSP might use wrong interpreter if venv not configured
- **Assertions for type narrowing**: `assert x is not None` tells type checker x is not None
- **Defensive programming**: Type checker warnings often catch real edge cases!

### Stable-Baselines3 Integration

- **SB3 DQN API**: Create with `DQN(policy, env, learning_rate, buffer_size, ...)`
- **CnnPolicy**: Built-in CNN architecture for image observations (no need to define network!)
- **Hyperparameter passing**: All DQN hyperparameters passed as constructor arguments
- **model.learn()**: Single call to train - SB3 handles the entire training loop
- **Verbosity levels**: verbose=1 shows training progress, verbose=0 is silent

### Callback Pattern in RL

- **BaseCallback**: Inherit and override `_on_step()` method
- **Event hooks**: Callbacks called at specific moments (after step, after rollout, etc.)
- **self.locals**: Dictionary containing training state (dones, infos, rewards, etc.)
- **episode_info**: Only exists when episode completes, must check with `.get("episode")`
- **Return True**: Callbacks return True to continue training, False to stop early
- **Multiple callbacks**: Pass list of callbacks to model.learn()

### Training Pipeline Architecture

- **Orchestrator pattern**: main() coordinates components, doesn't implement logic
- **Config-driven design**: YAML file controls all parameters, CLI args override for testing
- **Initialization order matters**: wandb â†’ database â†’ environment â†’ model â†’ callbacks â†’ train
- **Cleanup protocol**: Close environment, finish wandb session after training
- **Checkpoint strategy**: Save periodically during training (100k steps) + final model at end

### argparse for CLI

- **ArgumentParser**: Create parser, add arguments, call parse_args()
- **required vs optional**: required=True for mandatory args, default=value for optional
- **Type conversion**: type=str, type=int automatically converts string inputs
- **Help text**: Shows when user runs --help flag

## ðŸ’¡ Challenges & Solutions

### Challenge 1: Understanding DQN Bootstrapping

**Problem**: Confused about how network can create its own training labels
**Solution**: Realized it's iterative - each training step uses slightly better Q-estimates to create slightly better labels. Like climbing a ladder using previous rungs!

### Challenge 2: YAML Syntax Errors

**Problem**: Included Python imports in YAML file, typos in keys
**Solution**: Learned YAML is pure data, removed imports, fixed typos (algorithm, environment)

### Challenge 3: Config Loader Import Errors

**Problem**: `ModuleNotFoundError: No module named 'src'` when running test
**Solution**: Python imports relative to script location. Moved test to project root where it can see src/

### Challenge 4: Database Function Typos and Logic Errors

**Problem**: Multiple typos (hyperparams â†’ hyperparams_dict, gotchone â†’ fetchone), wrong indentation, fetchone() outside loop
**Solution**: Systematic code review, fixed variable names, moved cursor.execute() inside loop, removed unnecessary RETURNING clauses

### Challenge 5: Pyright Type Errors for Cursor

**Problem**: LSP warnings: "cursor possibly unbound", "execute not known attribute of None"
**Solution**:
1. Initialize `cursor: Optional[Cursor] = None` before try block
2. Add `assert cursor is not None` after creating cursor
3. Check `if cursor:` before closing in finally block
4. Fixed all 5 database functions with proper defensive programming

### Challenge 6: Action Space Parameter Not Used

**Problem**: `make_mario_env()` had `game_version` parameter but hardcoded "SuperMarioBros-v3"
**Solution**: Changed to use `game_version` parameter for configurability

### Challenge 7: Confusion Between Function Arguments and Dictionaries

**Problem**: Tried to call `db_logger.log_episode({...})` with dictionary syntax instead of function arguments
**Solution**: Learned difference between function calls (positional/keyword args) vs. creating dictionaries. Used keyword arguments for clarity.

### Challenge 8: Indentation Bug in DatabaseCallback

**Problem**: `db_logger.log_episode()` call was outside the `if episode_info is not None:` block, would crash on None
**Solution**: Indented entire function call to be inside the if block - defensive programming prevents crashes

### Challenge 9: Over-Explaining vs. Direct Feedback

**Problem**: Asked for confirmation on syntax but got long explanation instead of quick "yes, just change : to ="
**Solution**: Provided feedback to Claude about being more concise when close to correct answer - balance teaching with efficiency

### Evening Session: Training Pipeline Implementation

**Task 5: Training Script Structure** âœ…
- [x] Created `src/training/train.py` with complete orchestration
- [x] Implemented argument parser (--config, --experiment-name, --total-timesteps)
- [x] Built main() function coordinating all components
- [x] Integrated wandb initialization with config values
- [x] Wired up database experiment creation and hyperparameter logging
- [x] Created environment using make_mario_env helper
- [x] Initialized DQN agent with all hyperparameters from config

**Task 6: Custom Callbacks** âœ…
- [x] Created `src/training/callbacks.py` with two custom callbacks
- [x] Implemented WandbCallback for real-time cloud logging
- [x] Implemented DatabaseCallback for PostgreSQL episode logging
- [x] Integrated CheckpointCallback for model saving every 100k steps
- [x] Wired all callbacks into model.learn() call

**Task 7: LSP Error Resolution** âœ…
- [x] Fixed typos (DatabaseCallbacck â†’ DatabaseCallback)
- [x] Fixed variable names (experiment â†’ experiment_id)
- [x] Removed unused imports (Path, JoypadSpace, EvalCallback)
- [x] Fixed indentation bug in DatabaseCallback
- [x] Resolved all critical LSP warnings

## ðŸ”œ Tomorrow's Focus

- [ ] Add missing callback imports to train.py
- [ ] Run short test training (1000 timesteps) to verify pipeline
- [ ] Debug any issues that arise
- [ ] Run full DQN training (2M timesteps)
- [ ] Watch Mario actually LEARN! ðŸŽ®

## ðŸ”— Links & Context

- [[ProjectDocumentation]] - Updated Phase 3 progress (4/10 tasks complete)
- [[2025-12-31|Yesterday]] - Completed Phase 2
- Configuration: `configs/dqn_baseline.yaml`
- Config loader: `src/utils/config_loader.py`
- Environment helper: `src/environments/mario_env.py`
- Database utilities: `src/utils/db_logger.py`

## ðŸ’» Code/Commands Used

```bash
# Install dependencies
poetry add pyyaml
poetry add psycopg2-binary  # Already had from Phase 1
poetry add "opencv-python<4.11"  # Phase 2

# Test config loader
poetry run python test_config.py

# Test Mario environment with simplified actions
poetry run python test_env.py
```

```python
# Config loader (src/utils/config_loader.py)
import yaml

def load_config(config_path):
    with open(config_path, "r") as f:
        config = yaml.safe_load(f)
    return config

# Usage
config = load_config("configs/dqn_baseline.yaml")
print(config["experiment"]["name"])  # "dqn_baseline_world1-1"
```

```python
# Mario environment helper (src/environments/mario_env.py)
def make_mario_env(game_version="SuperMarioBros-v3", action_space=SIMPLE_MOVEMENT):
    env = gym_super_mario_bros.make(game_version, apply_api_compatibility=True)
    env = JoypadSpace(env, action_space)  # 256 â†’ 7 actions!
    env = GrayscaleWrapper(env)
    env = ResizeWrapper(env)
    env = NormalizeWrapper(env)
    env = FrameStackWrapper(env)
    return env
```

```python
# Database connection pool (src/utils/db_logger.py)
from psycopg2 import pool

_connection_pool = None

def get_connection_pool():
    global _connection_pool
    if _connection_pool is None:
        _connection_pool = pool.SimpleConnectionPool(
            minconn=1, maxconn=5,
            host="localhost", database="mario_rl_db",
            user="mario_rl_user", password="..."
        )
    return _connection_pool

# Usage in logging functions
def create_experiment(...):
    pool = get_connection_pool()
    conn = pool.getconn()
    cursor: Optional[Cursor] = None

    try:
        cursor = conn.cursor()
        assert cursor is not None
        # ... execute queries ...
        conn.commit()
    except Exception as e:
        conn.rollback()
        raise
    finally:
        if cursor:
            cursor.close()
        pool.putconn(conn)  # Return to pool, don't close!
```

## ðŸ“ Notes

**Epic productivity day!** Completed nearly all of Phase 3 infrastructure in one day - from morning DQN learning to evening training pipeline implementation. The full pipeline is now ready to run!

**Morning session (4 hours)**: Deep conceptual learning of DQN before writing code. This "understand first, implement second" approach paid off - when building the evening training script, I knew exactly WHY each component was needed.

**Evening session (4+ hours)**: Built complete training pipeline from scratch. Created train.py with argument parsing, wandb/database initialization, environment creation, DQN integration, and custom callbacks. Wrote WandbCallback and DatabaseCallback to automatically log during training.

**Key learning moment - function arguments**: Hit confusion between function calls and dictionaries. Tried `function({key: value})` instead of `function(param=value)`. Once clarified, understood the difference between passing a dict as one argument vs. passing individual keyword arguments.

**Callback pattern understanding**: Callbacks are event hooks - SB3 calls your `_on_step()` method at specific moments. You don't manually log during training; callbacks do it automatically. This is the observer pattern in action!

**Teaching style feedback**: Learned to speak up when explanations are too verbose. Sometimes "yes, just change : to =" is better than a long explanation. Balance is key.

**Phase 3 progress: 85% complete (11/12 tasks)**
- âœ… DQN conceptual learning
- âœ… YAML configuration system
- âœ… Config loader utility
- âœ… Environment helper with simplified actions
- âœ… Database logging utilities (5 functions)
- âœ… Training script with argument parsing
- âœ… Stable-Baselines3 DQN integration
- âœ… WandbCallback implementation
- âœ… DatabaseCallback implementation
- âœ… Checkpoint callback integration
- âœ… LSP error resolution
- â³ **Tomorrow: First training run!**

**Artifacts created today:**
- `configs/dqn_baseline.yaml` - Complete experiment configuration
- `src/utils/config_loader.py` - YAML configuration loader
- `src/environments/mario_env.py` - Environment helper with SIMPLE_MOVEMENT
- `src/utils/db_logger.py` - Database logging with connection pooling (5 functions)
- `src/training/train.py` - Complete training orchestrator (100+ lines)
- `src/training/callbacks.py` - Custom WandbCallback and DatabaseCallback

**Connection to cybersecurity goals:**
- Argument parsing applies to security tool CLIs
- Callback pattern mirrors security event handlers (SIEM, IDS)
- Orchestrator pattern applies to security automation pipelines
- Configuration management critical for security tool deployment
- Defensive programming (None checks, type safety) prevents vulnerabilities

**Tomorrow's plan**: Add one missing import, run 1000-step test to verify pipeline, then launch full 2M timestep training. After months of setup, we finally get to watch Mario LEARN!

_Session 1: 9:00 AM - 1:00 PM (Morning - DQN learning + utilities)_
_Session 2: 6:00 PM - 10:30 PM (Evening - Training pipeline + callbacks)_
_Total: ~8.5 hours of focused learning and coding!_

**Ready to train! ðŸš€ Phase 3 infrastructure complete - Mario's about to get smart!**

[[daily]]
