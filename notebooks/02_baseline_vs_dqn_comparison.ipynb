{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a36467-9061-46e6-bb68-b796d61669b7",
   "metadata": {},
   "source": [
    "## Phase 3 Anlaysis - January 2026\n",
    "This notebook compares the performance of our trained DQN agent against the random baseline fro\n",
    "m Phase 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0e689-80e7-4203-83c4-82cc7b1bb50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Database connection\n",
    "import psycopg2\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Statistics\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook' \n",
    "\n",
    "print(\"✅ Imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388535f-a1db-4dce-8529-9e6cf9c53d7d",
   "metadata": {},
   "source": [
    "## Load Experiment Data\n",
    "\n",
    "  We'll load episode metrics from two experiments:\n",
    "  1. Random baseline (Phase 2)\n",
    "  2. Trained DQN agent (Phase 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064767bc-6323-4ab7-873c-9141c5413f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "conn = psycopg2.connect(\n",
    "  host=\"localhost\",\n",
    "  database=\"mario_rl_db\",\n",
    "  user=\"mario_rl_user\",\n",
    "  password=\"Bingbongbing123!\"\n",
    ")\n",
    "\n",
    "print(\"✅ Connected to database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9c270-fa0f-4a69-8875-246396f7a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find our experiments\n",
    "query = \"\"\"\n",
    "SELECT experiment_id, experiment_name, algorithm, start_timestamp, total_episodes\n",
    "FROM experiments\n",
    "ORDER BY start_timestamp;\n",
    "\"\"\"\n",
    "\n",
    "experiments_df = pd.read_sql(query, conn)\n",
    "print(experiments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11d912-0865-4a9b-8c2b-63ab99d3854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all episodes for both experiments\n",
    "query_random = \"\"\"\n",
    "SELECT * FROM episodes \n",
    "WHERE experiment_id = 15\n",
    "ORDER BY episode_number;\n",
    "\"\"\"\n",
    "\n",
    "query_dqn = \"\"\"\n",
    "SELECT * FROM episodes \n",
    "WHERE experiment_id = 14\n",
    "ORDER BY episode_number;\n",
    "\"\"\"\n",
    "\n",
    "random_df = pd.read_sql(query_random, conn)\n",
    "dqn_df = pd.read_sql(query_dqn, conn)\n",
    "\n",
    "print(f\"Random baseline: {len(random_df)} episodes\")\n",
    "print(f\"DQN training: {len(dqn_df)} episodes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f329b-6690-487e-b0a3-a63bfbcfc454",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "  Let's compare the two agents across key metrics:\n",
    "  - Reward\n",
    "  - Distance traveled\n",
    "  - Score\n",
    "  - Success rate (flag_get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee49e6b-f172-4a0f-8589-fb89f6f36753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics for key metrics\n",
    "metrics = ['reward', 'distance_traveled', 'score']\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for metric in metrics:\n",
    "  summary_data.append({\n",
    "      'Metric': metric,\n",
    "      'Random Mean': random_df[metric].mean(),\n",
    "      'Random Std': random_df[metric].std(),\n",
    "      'DQN Mean': dqn_df[metric].mean(),\n",
    "      'DQN Std': dqn_df[metric].std(),\n",
    "      'Improvement': dqn_df[metric].mean() / random_df[metric].mean()\n",
    "  })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f8ebb-fc78-4623-bca3-5464c6792d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate success rates\n",
    "random_success = (random_df['level_completed'].sum() / len(random_df)) * 100\n",
    "dqn_success = (dqn_df['level_completed'].sum() / len(dqn_df)) * 100\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"SUCCESS RATE COMPARISON\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Random Agent:  {random_success:.1f}% ({random_df['level_completed'].sum()}/{len(random_df)} episodes)\")\n",
    "print(f\"DQN Agent:     {dqn_success:.1f}% ({dqn_df['level_completed'].sum()}/{len(dqn_df)} episodes)\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7204c73-0fe6-43c8-840c-9aff685f276f",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "Visual comparison of agent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9ea18-3bed-44cc-a5b0-9039555cad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe for plotting\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "  y=random_df['reward'],\n",
    "  name='Random Agent',\n",
    "  marker_color='coral',  # Changed to coral (reddish-orange)\n",
    "  line=dict(width=2)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "  y=dqn_df['reward'],\n",
    "  name='DQN Agent',\n",
    "  marker_color='mediumseagreen',  # Changed to medium sea green\n",
    "  line=dict(width=2)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "  title='Reward Distribution: Random vs DQN',\n",
    "  yaxis_title='Episode Reward',\n",
    "  showlegend=True,\n",
    "  height=500,\n",
    "  plot_bgcolor='white',\n",
    "  paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b028d-a7ac-4039-9157-4179664b18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve with better colors\n",
    "fig = go.Figure()\n",
    "\n",
    "# Episode rewards - darker with more opacity\n",
    "fig.add_trace(go.Scatter(\n",
    "  x=dqn_df['episode_number'],\n",
    "  y=dqn_df['reward'],\n",
    "  mode='markers',\n",
    "  name='Episode Reward',\n",
    "  marker=dict(size=4, color='steelblue'),  # Changed to steelblue, bigger markers\n",
    "  opacity=0.6  # Increased opacity\n",
    "))\n",
    "\n",
    "# Rolling average - bright contrasting color\n",
    "window = 50\n",
    "dqn_df['reward_ma'] = dqn_df['reward'].rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "  x=dqn_df['episode_number'],\n",
    "  y=dqn_df['reward_ma'],\n",
    "  mode='lines',\n",
    "  name=f'{window}-Episode Moving Average',\n",
    "  line=dict(color='green', width=4)  # Changed to green, thicker line\n",
    "))\n",
    "\n",
    "# Random baseline - bolder red\n",
    "fig.add_hline(y=360.4, line_dash=\"dash\", line_color=\"red\",\n",
    "            line_width=3,  # Thicker line\n",
    "            annotation_text=\"Random Baseline (360.4)\")\n",
    "\n",
    "fig.update_layout(\n",
    "  title='DQN Learning Curve: Reward Over Training',\n",
    "  xaxis_title='Episode Number',\n",
    "  yaxis_title='Reward',\n",
    "  height=500,\n",
    "  plot_bgcolor='white',  # White background\n",
    "  paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3107c-a391-43b8-86ad-12cd3d89c171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
